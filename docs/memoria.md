# üíä Pharma Sales Forecasting & Analytics ‚Äî Memoria T√©cnica  

## üìå Introducci√≥n y objetivos  
El objetivo del proyecto es **predecir las ventas de f√°rmacos** en distintas granularidades temporales (horaria, diaria, semanal y mensual) utilizando t√©cnicas de Machine Learning y an√°lisis de series temporales.  
Se busca no solo generar predicciones precisas, sino tambi√©n:  
- **Identificar patrones de consumo** (estacionalidad, ciclos, variaciones semanales).  
- **Detectar categor√≠as dominantes** de medicamentos.  
- **Aportar valor de negocio** mediante un dashboard interactivo en Streamlit que permita explorar los resultados.  

---

Adem√°s del enfoque t√©cnico, este proyecto tiene un **impacto directo en negocio**:

- **Farmacias y distribuidores locales**: optimizan inventario antes de picos de demanda (ej. temporada de gripe), evitan roturas de stock de medicamentos cr√≠ticos y mejoran la eficiencia en pedidos semanales.  
- **Laboratorios farmac√©uticos**: planifican la producci√≥n con meses de antelaci√≥n, detectan qu√© categor√≠as ATC ganan relevancia y ajustan campa√±as de marketing seg√∫n la estacionalidad.  
- **Gestores estrat√©gicos**: identifican tendencias de largo plazo (ej. aumento en ansiol√≠ticos post-pandemia), deciden en qu√© categor√≠as invertir m√°s recursos y cuantifican el impacto econ√≥mico de reducir el error de predicci√≥n (ej. *MAPE < 2% implica ahorro en sobrestock*).  

---

## üìä Fuente de datos (Kaggle)  
El dataset utilizado proviene de:  
**[Kaggle: Pharma Sales Data](https://www.kaggle.com/datasets/milanzdravkovic/pharma-sales-data)**  

- Registros de ventas desagregadas por c√≥digo **ATC**.  
- Cuatro granularidades: **Hourly, Daily, Weekly, Monthly**.  
- Columnas principales:  
  - `datum`: fecha de la observaci√≥n.  
  - `M01AB`, `M01AE`, `N02BA`, `N02BE`, `N05B`, `N05C`, `R03`, `R06`: ventas por categor√≠a.  
  - `Total sales`: suma de todas las categor√≠as (calculada en el procesamiento).  

---

## üõ†Ô∏è Procesamiento de datos  
Se implement√≥ un **pipeline reproducible en Python** (`src/data_processing.py`) que:  
1. **Convierte las fechas** a formato datetime y ordena las series.  
2. **Calcula `Total sales`** como suma de todas las columnas ATC.  
3. **A√±ade variables temporales**:  
   - A√±o, mes, d√≠a, d√≠a de la semana, hora (para granularidad horaria).  
4. **Genera features adicionales para Daily**:  
   - Lags (`lag_1`, `lag_7`)  
   - Medias m√≥viles (`roll7`)  
5. **Exporta datasets procesados** en `data/processed/` y artefactos de negocio en `docs/artifacts/`.  

---

## üìä Justificaci√≥n de la granularidad ‚Äî ¬øpor qu√© entrenamos con *Daily*?

Elegimos **Daily** como granularidad principal por un balance entre:
- Volumen suficiente de datos   
- Comparabilidad de m√©tricas   
- Escalabilidad hacia otras frecuencias   

---

### ‚è≥ ¬øPor qu√© no usamos `hourly/weekly/monthly`?

**1Ô∏è‚É£ Volumen y granularidad de los datos**

- **Daily (~2100 filas, ~6 a√±os)** ‚Üí suficiente para entrenar modelos supervisados robustos (RF, GBR, XGB, CatBoost).  
- **Hourly (~50k filas)** ‚Üí demasiado grande y ruidoso, dominado por patrones intradiarios (picos ma√±ana/tarde). M√°s adecuado para modelos de series de alta frecuencia (SARIMAX intradiario, Prophet con estacionalidad horaria) que para regresi√≥n cl√°sica.  
- **Weekly (302 filas)** y **Monthly (70 filas)** ‚Üí demasiado cortos para Random Forest/XGBoost ‚Üí alto riesgo de *overfitting*.  

**2Ô∏è‚É£ Comparabilidad**

- Los modelos supervisados necesitan la misma granularidad para que las m√©tricas (MAPE, MAE, etc.) sean comparables.  
- Si mezclamos Daily con Weekly/Monthly, las m√©tricas no ser√≠an equivalentes, ya que miden horizontes distintos.  
- Por eso fijamos **Daily** como dataset de referencia para entrenar y comparar modelos.  

---

### üìà Escalabilidad de entrenar s√≥lo con *Daily*

**1Ô∏è‚É£ Escalabilidad en negocio / forecast**

Un modelo entrenado en Daily puede **agregarse hacia arriba**:  
- Para Weekly ‚Üí sumar predicciones en bloques de 7 d√≠as.  
- Para Monthly ‚Üí agregaci√≥n de los d√≠as de cada mes.  
- Esto permite escalar Daily hacia granularidades superiores sin p√©rdida de comparabilidad.  

El caso contrario (**Hourly ‚Üí Daily**) es m√°s costoso porque habr√≠a que suavizar mucho ruido y manejar grandes vol√∫menes de datos.  

**2Ô∏è‚É£ Limitaciones**

- **Horizonte largo de predicci√≥n**: a 6‚Äì12 meses, el error acumulado en Daily puede crecer ‚Üí en ese caso modelos mensuales podr√≠an ser m√°s estables.  
- **Big data futuro**: con datos de muchos pa√≠ses/a√±os, habr√≠a que pensar en pipelines distribuidos.  
- **No capta patrones intradiarios**: entrenar con Daily ignora los picos horarios (ma√±ana/tarde), aunque eso no afecta al escalado hacia semanas/meses.  

---

## ü§ñ Modelos probados  
Se implementaron y compararon distintos algoritmos de predicci√≥n:  

- **ARIMA / SARIMAX** ‚Üí Modelos cl√°sicos de series temporales.  
- **Random Forest Regressor** ‚Üí Ensamble de √°rboles de decisi√≥n.  
- **Gradient Boosting Regressor (GBR)** ‚Üí Boosting secuencial de √°rboles.  
- **XGBoost Regressor** ‚Üí Algoritmo optimizado de boosting.  
- **CatBoost Regressor** ‚Üí Modelo ganador üèÜ por su bajo error y estabilidad.  
- **KMeans Clustering** ‚Üí Segmentaci√≥n no supervisada de d√≠as de ventas.  
- *(Reservado para futuro)* **Prophet** para estacionalidad compleja.  

---

## üìè Evaluaci√≥n con m√©tricas  
Se evaluaron todos los modelos usando **test temporal (√∫ltimo 20%)** y m√©tricas est√°ndar:  

- **MAPE** (Error porcentual absoluto medio).  
- **MAE** (Error absoluto medio).  
- **MSE** (Error cuadr√°tico medio).  
- **R¬≤** (Coeficiente de determinaci√≥n).  

üìå **Resultados clave**:  
- **CatBoost (base)** alcanz√≥ un **MAPE < 2%** y R¬≤ ‚âà 0.99.  
- Otros modelos como XGBoost y GBR tuvieron desempe√±os cercanos, pero con ligeras desventajas.  
- Modelos cl√°sicos (ARIMA/SARIMAX) quedaron por debajo en precisi√≥n.  

---

## üß© Clustering y patrones detectados  
Mediante **KMeans** se agruparon d√≠as con patrones similares de ventas:  
- Se identificaron segmentos diferenciados de consumo (alta demanda, media, baja).  
- Permite detectar estacionalidad y posibles cambios de comportamiento.  

Patrones adicionales:  
- **Estacionalidad intra‚Äìanual**: mayor consumo en determinados meses.  
- **Patr√≥n semanal**: picos recurrentes en d√≠as laborales frente a fines de semana.  
- **Patr√≥n horario**: horas de mayor demanda concentradas en franjas espec√≠ficas.  

---

## üìä Visualizaciones clave  
- Series temporales de ventas.  
- Distribuciones (histogramas, KDE, boxplots).  
- Pareto y ranking de categor√≠as ATC.  
- Stacked de categor√≠as en el tiempo.  
- ACF / PACF para autocorrelaci√≥n y dependencia.  
- Resultados de clustering (PCA scatter, heatmap de medias).  
- Dashboard interactivo en **Streamlit** con:  
  - Filtros de granularidad y fechas.  
  - Visualizaci√≥n de m√©tricas y predicciones.  
  - Galer√≠a de plots.  

---

## üß† Explicabilidad y √©tica  
- **Importancia de variables**: se analizaron feature importances en RF, GBR, XGB y CatBoost.  
- **Sesgos potenciales**:  
  - Dependencia de datos hist√≥ricos ‚Üí riesgo si cambian patrones externos.  
  - Diferencias en categor√≠as con menor representaci√≥n.  
- **Mitigaciones**:  
  - Uso de varios modelos en paralelo.  
  - Evaluaci√≥n continua y actualizaci√≥n del pipeline.  
- **Consideraciones √©ticas**:  
  - La predicci√≥n de ventas no debe usarse para restringir disponibilidad de f√°rmacos esenciales.  
  - Transparencia en el uso del modelo mediante **memoria t√©cnica y dashboard**.  

---

## ‚úÖ Conclusiones y futuro  
- Se logr√≥ un **sistema de forecasting robusto** con precisi√≥n alta (MAPE < 2%).  
- El **CatBoost Regressor** fue el mejor modelo global.  
- El an√°lisis de categor√≠as y clustering aporta **valor de negocio** adicional.  

üìå **L√≠neas futuras**:  
- Integrar **Prophet** para capturar estacionalidad avanzada.  
- Ampliar despliegue con API y dashboard web escalable.  
- Incorporar explicabilidad m√°s profunda (SHAP values).  
- Monitorizar el modelo en producci√≥n con datos en tiempo real.  